{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3ab3326",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12f515de",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=pd.read_excel('Data_Train.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbaec247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airline</th>\n",
       "      <th>Date_of_Journey</th>\n",
       "      <th>Source</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Route</th>\n",
       "      <th>Dep_Time</th>\n",
       "      <th>Arrival_Time</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Total_Stops</th>\n",
       "      <th>Additional_Info</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IndiGo</td>\n",
       "      <td>24/03/2019</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>BLR → DEL</td>\n",
       "      <td>22:20</td>\n",
       "      <td>01:10 22 Mar</td>\n",
       "      <td>2h 50m</td>\n",
       "      <td>non-stop</td>\n",
       "      <td>No info</td>\n",
       "      <td>3897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Air India</td>\n",
       "      <td>1/05/2019</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>CCU → IXR → BBI → BLR</td>\n",
       "      <td>05:50</td>\n",
       "      <td>13:15</td>\n",
       "      <td>7h 25m</td>\n",
       "      <td>2 stops</td>\n",
       "      <td>No info</td>\n",
       "      <td>7662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jet Airways</td>\n",
       "      <td>9/06/2019</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>DEL → LKO → BOM → COK</td>\n",
       "      <td>09:25</td>\n",
       "      <td>04:25 10 Jun</td>\n",
       "      <td>19h</td>\n",
       "      <td>2 stops</td>\n",
       "      <td>No info</td>\n",
       "      <td>13882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IndiGo</td>\n",
       "      <td>12/05/2019</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>CCU → NAG → BLR</td>\n",
       "      <td>18:05</td>\n",
       "      <td>23:30</td>\n",
       "      <td>5h 25m</td>\n",
       "      <td>1 stop</td>\n",
       "      <td>No info</td>\n",
       "      <td>6218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IndiGo</td>\n",
       "      <td>01/03/2019</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>BLR → NAG → DEL</td>\n",
       "      <td>16:50</td>\n",
       "      <td>21:35</td>\n",
       "      <td>4h 45m</td>\n",
       "      <td>1 stop</td>\n",
       "      <td>No info</td>\n",
       "      <td>13302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Airline Date_of_Journey    Source Destination                  Route  \\\n",
       "0       IndiGo      24/03/2019  Banglore   New Delhi              BLR → DEL   \n",
       "1    Air India       1/05/2019   Kolkata    Banglore  CCU → IXR → BBI → BLR   \n",
       "2  Jet Airways       9/06/2019     Delhi      Cochin  DEL → LKO → BOM → COK   \n",
       "3       IndiGo      12/05/2019   Kolkata    Banglore        CCU → NAG → BLR   \n",
       "4       IndiGo      01/03/2019  Banglore   New Delhi        BLR → NAG → DEL   \n",
       "\n",
       "  Dep_Time  Arrival_Time Duration Total_Stops Additional_Info  Price  \n",
       "0    22:20  01:10 22 Mar   2h 50m    non-stop         No info   3897  \n",
       "1    05:50         13:15   7h 25m     2 stops         No info   7662  \n",
       "2    09:25  04:25 10 Jun      19h     2 stops         No info  13882  \n",
       "3    18:05         23:30   5h 25m      1 stop         No info   6218  \n",
       "4    16:50         21:35   4h 45m      1 stop         No info  13302  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86117a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Airline            0\n",
       "Date_of_Journey    0\n",
       "Source             0\n",
       "Destination        0\n",
       "Route              1\n",
       "Dep_Time           0\n",
       "Arrival_Time       0\n",
       "Duration           0\n",
       "Total_Stops        1\n",
       "Additional_Info    0\n",
       "Price              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28440ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8abf944d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10682 entries, 0 to 10682\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Airline          10682 non-null  object\n",
      " 1   Date_of_Journey  10682 non-null  object\n",
      " 2   Source           10682 non-null  object\n",
      " 3   Destination      10682 non-null  object\n",
      " 4   Route            10682 non-null  object\n",
      " 5   Dep_Time         10682 non-null  object\n",
      " 6   Arrival_Time     10682 non-null  object\n",
      " 7   Duration         10682 non-null  object\n",
      " 8   Total_Stops      10682 non-null  object\n",
      " 9   Additional_Info  10682 non-null  object\n",
      " 10  Price            10682 non-null  int64 \n",
      "dtypes: int64(1), object(10)\n",
      "memory usage: 1001.4+ KB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae04b485",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/03/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/06/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/05/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/04/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/04/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/04/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/03/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/05/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/06/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/06/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/05/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/06/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/05/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/03/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/05/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/04/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/06/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/03/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/03/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/04/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/03/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/06/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/05/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/04/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/04/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/04/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/03/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/05/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/06/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/06/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/05/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/06/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/05/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/03/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/05/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/04/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/06/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/03/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/03/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/04/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n"
     ]
    }
   ],
   "source": [
    "#EDA\n",
    "train_data['Journey_day']=pd.to_datetime(train_data['Date_of_Journey']).dt.day\n",
    "train_data['Journey_month']=pd.to_datetime(train_data['Date_of_Journey']).dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62d2ea8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airline</th>\n",
       "      <th>Date_of_Journey</th>\n",
       "      <th>Source</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Route</th>\n",
       "      <th>Dep_Time</th>\n",
       "      <th>Arrival_Time</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Total_Stops</th>\n",
       "      <th>Additional_Info</th>\n",
       "      <th>Price</th>\n",
       "      <th>Journey_day</th>\n",
       "      <th>Journey_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IndiGo</td>\n",
       "      <td>24/03/2019</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>BLR → DEL</td>\n",
       "      <td>22:20</td>\n",
       "      <td>01:10 22 Mar</td>\n",
       "      <td>2h 50m</td>\n",
       "      <td>non-stop</td>\n",
       "      <td>No info</td>\n",
       "      <td>3897</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Air India</td>\n",
       "      <td>1/05/2019</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>CCU → IXR → BBI → BLR</td>\n",
       "      <td>05:50</td>\n",
       "      <td>13:15</td>\n",
       "      <td>7h 25m</td>\n",
       "      <td>2 stops</td>\n",
       "      <td>No info</td>\n",
       "      <td>7662</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jet Airways</td>\n",
       "      <td>9/06/2019</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>DEL → LKO → BOM → COK</td>\n",
       "      <td>09:25</td>\n",
       "      <td>04:25 10 Jun</td>\n",
       "      <td>19h</td>\n",
       "      <td>2 stops</td>\n",
       "      <td>No info</td>\n",
       "      <td>13882</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IndiGo</td>\n",
       "      <td>12/05/2019</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>CCU → NAG → BLR</td>\n",
       "      <td>18:05</td>\n",
       "      <td>23:30</td>\n",
       "      <td>5h 25m</td>\n",
       "      <td>1 stop</td>\n",
       "      <td>No info</td>\n",
       "      <td>6218</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IndiGo</td>\n",
       "      <td>01/03/2019</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>BLR → NAG → DEL</td>\n",
       "      <td>16:50</td>\n",
       "      <td>21:35</td>\n",
       "      <td>4h 45m</td>\n",
       "      <td>1 stop</td>\n",
       "      <td>No info</td>\n",
       "      <td>13302</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Airline Date_of_Journey    Source Destination                  Route  \\\n",
       "0       IndiGo      24/03/2019  Banglore   New Delhi              BLR → DEL   \n",
       "1    Air India       1/05/2019   Kolkata    Banglore  CCU → IXR → BBI → BLR   \n",
       "2  Jet Airways       9/06/2019     Delhi      Cochin  DEL → LKO → BOM → COK   \n",
       "3       IndiGo      12/05/2019   Kolkata    Banglore        CCU → NAG → BLR   \n",
       "4       IndiGo      01/03/2019  Banglore   New Delhi        BLR → NAG → DEL   \n",
       "\n",
       "  Dep_Time  Arrival_Time Duration Total_Stops Additional_Info  Price  \\\n",
       "0    22:20  01:10 22 Mar   2h 50m    non-stop         No info   3897   \n",
       "1    05:50         13:15   7h 25m     2 stops         No info   7662   \n",
       "2    09:25  04:25 10 Jun      19h     2 stops         No info  13882   \n",
       "3    18:05         23:30   5h 25m      1 stop         No info   6218   \n",
       "4    16:50         21:35   4h 45m      1 stop         No info  13302   \n",
       "\n",
       "   Journey_day  Journey_month  \n",
       "0           24              3  \n",
       "1            5              1  \n",
       "2            6              9  \n",
       "3            5             12  \n",
       "4            3              1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33eba130",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop('Date_of_Journey',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1566c38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arrival time\n",
    "train_data['Arrival_hour']=pd.to_datetime(train_data['Arrival_Time']).dt.hour\n",
    "train_data['Arrival_mins']=pd.to_datetime(train_data['Arrival_Time']).dt.minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "897578e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop('Arrival_Time',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c669ab5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#departure Time\n",
    "train_data['Dep_hour']=pd.to_datetime(train_data['Dep_Time']).dt.hour\n",
    "train_data['Dep_min']=pd.to_datetime(train_data['Dep_Time']).dt.minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2875757a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop('Dep_Time',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee56ad0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning and converting Duration column into list\n",
    "duration = list(train_data[\"Duration\"])\n",
    "\n",
    "for i in range(len(duration)):\n",
    "    if len(duration[i].split()) != 2:    # Check if duration contains only hour or mins\n",
    "        if \"h\" in duration[i]:\n",
    "            duration[i] = duration[i].strip() + \" 0m\"   # Adds 0 minute\n",
    "        else:\n",
    "            duration[i] = \"0h \" + duration[i]           # Adds 0 hour\n",
    "\n",
    "duration_hours = []\n",
    "duration_mins = []\n",
    "for i in range(len(duration)):\n",
    "    duration_hours.append(int(duration[i].split(sep = \"h\")[0]))    # Extract hours from duration\n",
    "    duration_mins.append(int(duration[i].split(sep = \"m\")[0].split()[-1]))   # Extracts only minutes from duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "107814a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Duration_min']=duration_mins\n",
    "train_data['Duration_hour']=duration_hours\n",
    "train_data.drop('Duration',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d28e8346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airline</th>\n",
       "      <th>Source</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Route</th>\n",
       "      <th>Total_Stops</th>\n",
       "      <th>Additional_Info</th>\n",
       "      <th>Price</th>\n",
       "      <th>Journey_day</th>\n",
       "      <th>Journey_month</th>\n",
       "      <th>Arrival_hour</th>\n",
       "      <th>Arrival_mins</th>\n",
       "      <th>Dep_hour</th>\n",
       "      <th>Dep_min</th>\n",
       "      <th>Duration_min</th>\n",
       "      <th>Duration_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IndiGo</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>BLR → DEL</td>\n",
       "      <td>non-stop</td>\n",
       "      <td>No info</td>\n",
       "      <td>3897</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Air India</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>CCU → IXR → BBI → BLR</td>\n",
       "      <td>2 stops</td>\n",
       "      <td>No info</td>\n",
       "      <td>7662</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jet Airways</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>DEL → LKO → BOM → COK</td>\n",
       "      <td>2 stops</td>\n",
       "      <td>No info</td>\n",
       "      <td>13882</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IndiGo</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>CCU → NAG → BLR</td>\n",
       "      <td>1 stop</td>\n",
       "      <td>No info</td>\n",
       "      <td>6218</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "      <td>30</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IndiGo</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>BLR → NAG → DEL</td>\n",
       "      <td>1 stop</td>\n",
       "      <td>No info</td>\n",
       "      <td>13302</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>35</td>\n",
       "      <td>16</td>\n",
       "      <td>50</td>\n",
       "      <td>45</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Airline    Source Destination                  Route Total_Stops  \\\n",
       "0       IndiGo  Banglore   New Delhi              BLR → DEL    non-stop   \n",
       "1    Air India   Kolkata    Banglore  CCU → IXR → BBI → BLR     2 stops   \n",
       "2  Jet Airways     Delhi      Cochin  DEL → LKO → BOM → COK     2 stops   \n",
       "3       IndiGo   Kolkata    Banglore        CCU → NAG → BLR      1 stop   \n",
       "4       IndiGo  Banglore   New Delhi        BLR → NAG → DEL      1 stop   \n",
       "\n",
       "  Additional_Info  Price  Journey_day  Journey_month  Arrival_hour  \\\n",
       "0         No info   3897           24              3             1   \n",
       "1         No info   7662            5              1            13   \n",
       "2         No info  13882            6              9             4   \n",
       "3         No info   6218            5             12            23   \n",
       "4         No info  13302            3              1            21   \n",
       "\n",
       "   Arrival_mins  Dep_hour  Dep_min  Duration_min  Duration_hour  \n",
       "0            10        22       20            50              2  \n",
       "1            15         5       50            25              7  \n",
       "2            25         9       25             0             19  \n",
       "3            30        18        5            25              5  \n",
       "4            35        16       50            45              4  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4c4a99e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Airline            0\n",
       "Source             0\n",
       "Destination        0\n",
       "Route              0\n",
       "Total_Stops        0\n",
       "Additional_Info    0\n",
       "Price              0\n",
       "Journey_day        0\n",
       "Journey_month      0\n",
       "Arrival_hour       0\n",
       "Arrival_mins       0\n",
       "Dep_hour           0\n",
       "Dep_min            0\n",
       "Duration_min       0\n",
       "Duration_hour      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82b9b31c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No info                         8344\n",
       "In-flight meal not included     1982\n",
       "No check-in baggage included     320\n",
       "1 Long layover                    19\n",
       "Change airports                    7\n",
       "Business class                     4\n",
       "No Info                            3\n",
       "1 Short layover                    1\n",
       "Red-eye flight                     1\n",
       "2 Long layover                     1\n",
       "Name: Additional_Info, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['Additional_Info'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8eb664ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "##ONE HOT ENCODING FOR NOMINAL DATA:\n",
    "train_data=pd.get_dummies(train_data,columns=['Airline','Source','Destination'],drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "481d3cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#80% records have no info\n",
    "train_data.drop('Additional_Info',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7056ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Route is related to no. of stops\n",
    "train_data.drop('Route',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f7c1608b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['non-stop', '2 stops', '1 stop', '3 stops', '4 stops'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#No. Of Stops(Ordinal Encoding)\n",
    "train_data['Total_Stops'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "038db61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Total_Stops']=train_data['Total_Stops'].map({'non-stop':0, '2 stops':2, '1 stop':1, '3 stops':3, '4 stops':4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "400cfba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total_Stops</th>\n",
       "      <th>Price</th>\n",
       "      <th>Journey_day</th>\n",
       "      <th>Journey_month</th>\n",
       "      <th>Arrival_hour</th>\n",
       "      <th>Arrival_mins</th>\n",
       "      <th>Dep_hour</th>\n",
       "      <th>Dep_min</th>\n",
       "      <th>Duration_min</th>\n",
       "      <th>Duration_hour</th>\n",
       "      <th>...</th>\n",
       "      <th>Airline_Vistara Premium economy</th>\n",
       "      <th>Source_Chennai</th>\n",
       "      <th>Source_Delhi</th>\n",
       "      <th>Source_Kolkata</th>\n",
       "      <th>Source_Mumbai</th>\n",
       "      <th>Destination_Cochin</th>\n",
       "      <th>Destination_Delhi</th>\n",
       "      <th>Destination_Hyderabad</th>\n",
       "      <th>Destination_Kolkata</th>\n",
       "      <th>Destination_New Delhi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3897</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>7662</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>13882</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6218</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "      <td>30</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13302</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>35</td>\n",
       "      <td>16</td>\n",
       "      <td>50</td>\n",
       "      <td>45</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Total_Stops  Price  Journey_day  Journey_month  Arrival_hour  Arrival_mins  \\\n",
       "0            0   3897           24              3             1            10   \n",
       "1            2   7662            5              1            13            15   \n",
       "2            2  13882            6              9             4            25   \n",
       "3            1   6218            5             12            23            30   \n",
       "4            1  13302            3              1            21            35   \n",
       "\n",
       "   Dep_hour  Dep_min  Duration_min  Duration_hour  ...  \\\n",
       "0        22       20            50              2  ...   \n",
       "1         5       50            25              7  ...   \n",
       "2         9       25             0             19  ...   \n",
       "3        18        5            25              5  ...   \n",
       "4        16       50            45              4  ...   \n",
       "\n",
       "   Airline_Vistara Premium economy  Source_Chennai  Source_Delhi  \\\n",
       "0                                0               0             0   \n",
       "1                                0               0             0   \n",
       "2                                0               0             1   \n",
       "3                                0               0             0   \n",
       "4                                0               0             0   \n",
       "\n",
       "   Source_Kolkata  Source_Mumbai  Destination_Cochin  Destination_Delhi  \\\n",
       "0               0              0                   0                  0   \n",
       "1               1              0                   0                  0   \n",
       "2               0              0                   1                  0   \n",
       "3               1              0                   0                  0   \n",
       "4               0              0                   0                  0   \n",
       "\n",
       "   Destination_Hyderabad  Destination_Kolkata  Destination_New Delhi  \n",
       "0                      0                    0                      1  \n",
       "1                      0                    0                      0  \n",
       "2                      0                    0                      0  \n",
       "3                      0                    0                      0  \n",
       "4                      0                    0                      1  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "44a17d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10682, 30)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "270375aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10682 entries, 0 to 10682\n",
      "Data columns (total 30 columns):\n",
      " #   Column                                     Non-Null Count  Dtype\n",
      "---  ------                                     --------------  -----\n",
      " 0   Total_Stops                                10682 non-null  int64\n",
      " 1   Price                                      10682 non-null  int64\n",
      " 2   Journey_day                                10682 non-null  int64\n",
      " 3   Journey_month                              10682 non-null  int64\n",
      " 4   Arrival_hour                               10682 non-null  int64\n",
      " 5   Arrival_mins                               10682 non-null  int64\n",
      " 6   Dep_hour                                   10682 non-null  int64\n",
      " 7   Dep_min                                    10682 non-null  int64\n",
      " 8   Duration_min                               10682 non-null  int64\n",
      " 9   Duration_hour                              10682 non-null  int64\n",
      " 10  Airline_Air India                          10682 non-null  uint8\n",
      " 11  Airline_GoAir                              10682 non-null  uint8\n",
      " 12  Airline_IndiGo                             10682 non-null  uint8\n",
      " 13  Airline_Jet Airways                        10682 non-null  uint8\n",
      " 14  Airline_Jet Airways Business               10682 non-null  uint8\n",
      " 15  Airline_Multiple carriers                  10682 non-null  uint8\n",
      " 16  Airline_Multiple carriers Premium economy  10682 non-null  uint8\n",
      " 17  Airline_SpiceJet                           10682 non-null  uint8\n",
      " 18  Airline_Trujet                             10682 non-null  uint8\n",
      " 19  Airline_Vistara                            10682 non-null  uint8\n",
      " 20  Airline_Vistara Premium economy            10682 non-null  uint8\n",
      " 21  Source_Chennai                             10682 non-null  uint8\n",
      " 22  Source_Delhi                               10682 non-null  uint8\n",
      " 23  Source_Kolkata                             10682 non-null  uint8\n",
      " 24  Source_Mumbai                              10682 non-null  uint8\n",
      " 25  Destination_Cochin                         10682 non-null  uint8\n",
      " 26  Destination_Delhi                          10682 non-null  uint8\n",
      " 27  Destination_Hyderabad                      10682 non-null  uint8\n",
      " 28  Destination_Kolkata                        10682 non-null  uint8\n",
      " 29  Destination_New Delhi                      10682 non-null  uint8\n",
      "dtypes: int64(10), uint8(20)\n",
      "memory usage: 1.1 MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8cb196f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10682, 30)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5765ad10",
   "metadata": {},
   "source": [
    "# TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "27aff0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=pd.read_excel(\"Test_Set.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "44c44654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airline</th>\n",
       "      <th>Date_of_Journey</th>\n",
       "      <th>Source</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Route</th>\n",
       "      <th>Dep_Time</th>\n",
       "      <th>Arrival_Time</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Total_Stops</th>\n",
       "      <th>Additional_Info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jet Airways</td>\n",
       "      <td>6/06/2019</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>DEL → BOM → COK</td>\n",
       "      <td>17:30</td>\n",
       "      <td>04:25 07 Jun</td>\n",
       "      <td>10h 55m</td>\n",
       "      <td>1 stop</td>\n",
       "      <td>No info</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IndiGo</td>\n",
       "      <td>12/05/2019</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>CCU → MAA → BLR</td>\n",
       "      <td>06:20</td>\n",
       "      <td>10:20</td>\n",
       "      <td>4h</td>\n",
       "      <td>1 stop</td>\n",
       "      <td>No info</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jet Airways</td>\n",
       "      <td>21/05/2019</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>DEL → BOM → COK</td>\n",
       "      <td>19:15</td>\n",
       "      <td>19:00 22 May</td>\n",
       "      <td>23h 45m</td>\n",
       "      <td>1 stop</td>\n",
       "      <td>In-flight meal not included</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Multiple carriers</td>\n",
       "      <td>21/05/2019</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>DEL → BOM → COK</td>\n",
       "      <td>08:00</td>\n",
       "      <td>21:00</td>\n",
       "      <td>13h</td>\n",
       "      <td>1 stop</td>\n",
       "      <td>No info</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Air Asia</td>\n",
       "      <td>24/06/2019</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>BLR → DEL</td>\n",
       "      <td>23:55</td>\n",
       "      <td>02:45 25 Jun</td>\n",
       "      <td>2h 50m</td>\n",
       "      <td>non-stop</td>\n",
       "      <td>No info</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Airline Date_of_Journey    Source Destination            Route  \\\n",
       "0        Jet Airways       6/06/2019     Delhi      Cochin  DEL → BOM → COK   \n",
       "1             IndiGo      12/05/2019   Kolkata    Banglore  CCU → MAA → BLR   \n",
       "2        Jet Airways      21/05/2019     Delhi      Cochin  DEL → BOM → COK   \n",
       "3  Multiple carriers      21/05/2019     Delhi      Cochin  DEL → BOM → COK   \n",
       "4           Air Asia      24/06/2019  Banglore       Delhi        BLR → DEL   \n",
       "\n",
       "  Dep_Time  Arrival_Time Duration Total_Stops              Additional_Info  \n",
       "0    17:30  04:25 07 Jun  10h 55m      1 stop                      No info  \n",
       "1    06:20         10:20       4h      1 stop                      No info  \n",
       "2    19:15  19:00 22 May  23h 45m      1 stop  In-flight meal not included  \n",
       "3    08:00         21:00      13h      1 stop                      No info  \n",
       "4    23:55  02:45 25 Jun   2h 50m    non-stop                      No info  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e016c78b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Airline            0\n",
       "Date_of_Journey    0\n",
       "Source             0\n",
       "Destination        0\n",
       "Route              0\n",
       "Dep_Time           0\n",
       "Arrival_Time       0\n",
       "Duration           0\n",
       "Total_Stops        0\n",
       "Additional_Info    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8c58b290",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/05/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/06/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/03/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/05/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/03/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/06/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/05/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/03/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/03/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/03/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/06/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/04/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/06/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/06/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/04/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/04/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/05/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/05/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/04/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/04/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/05/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/06/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/03/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/05/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/03/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/06/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/05/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/03/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/03/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/03/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/06/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/04/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/06/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/06/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/04/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/04/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/05/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/05/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/04/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/04/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n"
     ]
    }
   ],
   "source": [
    "test_data['Journey_day']=pd.to_datetime(test_data['Date_of_Journey']).dt.day\n",
    "test_data['Journey_month']=pd.to_datetime(test_data['Date_of_Journey']).dt.month\n",
    "test_data.drop('Date_of_Journey',axis=1,inplace=True)\n",
    "test_data['Arrival_hour']=pd.to_datetime(test_data['Arrival_Time']).dt.hour\n",
    "test_data['Arrival_mins']=pd.to_datetime(test_data['Arrival_Time']).dt.minute\n",
    "test_data['Dep_hour']=pd.to_datetime(test_data['Dep_Time']).dt.hour\n",
    "test_data['Dep_min']=pd.to_datetime(test_data['Dep_Time']).dt.minute\n",
    "test_data['Hour']=test_data['Duration'].str.split(' ').str[0]\n",
    "test_data['min']=test_data['Duration'].str.split(' ').str[1]\n",
    "test_data['Duration_hour']=test_data['Hour'].str.split('h').str[0]\n",
    "test_data['Duration_min']=test_data['min'].str.split('m').str[0]\n",
    "test_data.drop({'Hour','min','Duration'},axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "37026e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['Duration_min']=test_data['Duration_min'].replace(np.nan,0)\n",
    "test_data.drop('Additional_Info',axis=1,inplace=True)\n",
    "test_data.drop('Route',axis=1,inplace=True)\n",
    "test_data['Total_Stops']=test_data['Total_Stops'].map({'non-stop':0, '2 stops':2, '1 stop':1, '3 stops':3, '4 stops':4})\n",
    "test_data['Duration_min'].astype(int)\n",
    "test_data.drop('Arrival_Time',axis=1,inplace=True)\n",
    "test_data.drop('Dep_Time',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fc04dda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##ONE HOT ENCODING FOR NOMINAL DATA:\n",
    "test_data=pd.get_dummies(test_data,columns=['Airline','Source','Destination'],drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d2ec9a33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Total_Stops                                  0\n",
       "Journey_day                                  0\n",
       "Journey_month                                0\n",
       "Arrival_hour                                 0\n",
       "Arrival_mins                                 0\n",
       "Dep_hour                                     0\n",
       "Dep_min                                      0\n",
       "Duration_hour                                0\n",
       "Duration_min                                 0\n",
       "Airline_Air India                            0\n",
       "Airline_GoAir                                0\n",
       "Airline_IndiGo                               0\n",
       "Airline_Jet Airways                          0\n",
       "Airline_Jet Airways Business                 0\n",
       "Airline_Multiple carriers                    0\n",
       "Airline_Multiple carriers Premium economy    0\n",
       "Airline_SpiceJet                             0\n",
       "Airline_Vistara                              0\n",
       "Airline_Vistara Premium economy              0\n",
       "Source_Chennai                               0\n",
       "Source_Delhi                                 0\n",
       "Source_Kolkata                               0\n",
       "Source_Mumbai                                0\n",
       "Destination_Cochin                           0\n",
       "Destination_Delhi                            0\n",
       "Destination_Hyderabad                        0\n",
       "Destination_Kolkata                          0\n",
       "Destination_New Delhi                        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "50228a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2671, 28)\n",
      "(10682, 30)\n"
     ]
    }
   ],
   "source": [
    "print(test_data.shape)\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "46d955ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "Airline_Trujet =[0]*2671"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "83c1eeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['Airline_Trujet']=Airline_Trujet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "69fd604b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total_Stops</th>\n",
       "      <th>Journey_day</th>\n",
       "      <th>Journey_month</th>\n",
       "      <th>Arrival_hour</th>\n",
       "      <th>Arrival_mins</th>\n",
       "      <th>Dep_hour</th>\n",
       "      <th>Dep_min</th>\n",
       "      <th>Duration_hour</th>\n",
       "      <th>Duration_min</th>\n",
       "      <th>Airline_Air India</th>\n",
       "      <th>...</th>\n",
       "      <th>Source_Chennai</th>\n",
       "      <th>Source_Delhi</th>\n",
       "      <th>Source_Kolkata</th>\n",
       "      <th>Source_Mumbai</th>\n",
       "      <th>Destination_Cochin</th>\n",
       "      <th>Destination_Delhi</th>\n",
       "      <th>Destination_Hyderabad</th>\n",
       "      <th>Destination_Kolkata</th>\n",
       "      <th>Destination_New Delhi</th>\n",
       "      <th>Airline_Trujet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>17</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>23</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>23</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Total_Stops  Journey_day  Journey_month  Arrival_hour  Arrival_mins  \\\n",
       "0            1            6              6             4            25   \n",
       "1            1            5             12            10            20   \n",
       "2            1           21              5            19             0   \n",
       "3            1           21              5            21             0   \n",
       "4            0           24              6             2            45   \n",
       "\n",
       "   Dep_hour  Dep_min Duration_hour Duration_min  Airline_Air India  ...  \\\n",
       "0        17       30            10           55                  0  ...   \n",
       "1         6       20             4            0                  0  ...   \n",
       "2        19       15            23           45                  0  ...   \n",
       "3         8        0            13            0                  0  ...   \n",
       "4        23       55             2           50                  0  ...   \n",
       "\n",
       "   Source_Chennai  Source_Delhi  Source_Kolkata  Source_Mumbai  \\\n",
       "0               0             1               0              0   \n",
       "1               0             0               1              0   \n",
       "2               0             1               0              0   \n",
       "3               0             1               0              0   \n",
       "4               0             0               0              0   \n",
       "\n",
       "   Destination_Cochin  Destination_Delhi  Destination_Hyderabad  \\\n",
       "0                   1                  0                      0   \n",
       "1                   0                  0                      0   \n",
       "2                   1                  0                      0   \n",
       "3                   1                  0                      0   \n",
       "4                   0                  1                      0   \n",
       "\n",
       "   Destination_Kolkata  Destination_New Delhi  Airline_Trujet  \n",
       "0                    0                      0               0  \n",
       "1                    0                      0               0  \n",
       "2                    0                      0               0  \n",
       "3                    0                      0               0  \n",
       "4                    0                      0               0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0358268d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dependent & Independent Features:\n",
    "y=train_data['Price']\n",
    "X=train_data.drop('Price',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "24dffdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cc3a7102",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\balji\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "fvalue_selector=SelectKBest(f_classif,k=20)\n",
    "features_best=fvalue_selector.fit_transform(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f4d077ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([212.9745768 ,   3.34177483,   2.81694597,   4.78358966,\n",
       "         3.52723967,   3.03098245,   3.76083118,   3.28545742,\n",
       "        16.91890922, 157.32304812,  39.521078  ,  50.28948892,\n",
       "       338.23056941,          inf, 220.66052045,          inf,\n",
       "        34.09169438,          inf, 346.06246958,          inf,\n",
       "       212.0726247 , 228.95995614, 201.90335573, 224.43810789,\n",
       "       228.95995614,  98.16735027, 224.43810789, 212.0726247 ,\n",
       "        60.89757994])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fvalue_selector.scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2580052b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=features_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "172fa0f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 212.97457679909792\n",
      "1 : 3.3417748284099646\n",
      "2 : 2.8169459688244554\n",
      "3 : 4.783589655305923\n",
      "4 : 3.5272396683118745\n",
      "5 : 3.030982445785265\n",
      "6 : 3.7608311841110176\n",
      "7 : 3.2854574179923395\n",
      "8 : 16.918909215498974\n",
      "9 : 157.32304811887525\n",
      "10 : 39.521078002423565\n",
      "11 : 50.28948892186906\n",
      "12 : 338.23056940839484\n",
      "13 : inf\n",
      "14 : 220.6605204509278\n",
      "15 : inf\n",
      "16 : 34.0916943803233\n",
      "17 : inf\n",
      "18 : 346.06246957923037\n",
      "19 : inf\n",
      "20 : 212.07262469794074\n",
      "21 : 228.95995613975973\n",
      "22 : 201.90335573252867\n",
      "23 : 224.43810788987759\n",
      "24 : 228.95995613975973\n",
      "25 : 98.16735026706571\n",
      "26 : 224.43810788987759\n",
      "27 : 212.07262469794074\n",
      "28 : 60.89757994478171\n"
     ]
    }
   ],
   "source": [
    "for i in range (0,29):\n",
    "    print(i,\":\",fvalue_selector.scores_[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "06a96dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10682, 20)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "29dee400",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Test Split:\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c1e52fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "randomforest=RandomForestRegressor(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7cb1a448",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model1=randomforest.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5b52a74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=Model1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b55b6bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "90d5b4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 1835.7354588717274\n",
      "RMSE: 2743.157828807459\n"
     ]
    }
   ],
   "source": [
    "print('MAE:', metrics.mean_absolute_error(y_test,y_pred))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "05bea7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Hyperparameter Tunning using Randomized search cv:\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fe51e72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1200, num = 12)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(5, 30, num = 6)]\n",
    "min_samples_split = [2, 5, 10, 15, 100]\n",
    "min_samples_leaf = [1, 2, 5, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2c2a0c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4590cd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random = RandomizedSearchCV(estimator = randomforest, param_distributions = random_grid,scoring='neg_mean_squared_error', n_iter = 10, cv = 5, verbose=2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6638c19a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=900; total time=   1.1s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=900; total time=   1.1s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=900; total time=   1.1s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=900; total time=   1.1s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=900; total time=   1.1s\n",
      "[CV] END max_depth=30, max_features=auto, min_samples_leaf=10, min_samples_split=10, n_estimators=400; total time=   0.7s\n",
      "[CV] END max_depth=30, max_features=auto, min_samples_leaf=10, min_samples_split=10, n_estimators=400; total time=   0.7s\n",
      "[CV] END max_depth=30, max_features=auto, min_samples_leaf=10, min_samples_split=10, n_estimators=400; total time=   0.7s\n",
      "[CV] END max_depth=30, max_features=auto, min_samples_leaf=10, min_samples_split=10, n_estimators=400; total time=   0.7s\n",
      "[CV] END max_depth=30, max_features=auto, min_samples_leaf=10, min_samples_split=10, n_estimators=400; total time=   0.7s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=10, min_samples_split=10, n_estimators=1000; total time=   1.9s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=10, min_samples_split=10, n_estimators=1000; total time=   2.0s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=10, min_samples_split=10, n_estimators=1000; total time=   2.0s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=10, min_samples_split=10, n_estimators=1000; total time=   1.9s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=10, min_samples_split=10, n_estimators=1000; total time=   1.9s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=100, n_estimators=800; total time=   0.9s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=100, n_estimators=800; total time=   0.9s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=100, n_estimators=800; total time=   1.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=100, n_estimators=800; total time=   0.9s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=100, n_estimators=800; total time=   0.9s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=15, n_estimators=800; total time=   1.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=15, n_estimators=800; total time=   1.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=15, n_estimators=800; total time=   1.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=15, n_estimators=800; total time=   0.9s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=15, n_estimators=800; total time=   0.9s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=100, n_estimators=400; total time=   0.4s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=100, n_estimators=400; total time=   0.5s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=100, n_estimators=400; total time=   0.4s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=100, n_estimators=400; total time=   0.5s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=100, n_estimators=400; total time=   0.4s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=15, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=15, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=15, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=15, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=15, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=15, n_estimators=300; total time=   0.3s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=15, n_estimators=300; total time=   0.3s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=15, n_estimators=300; total time=   0.3s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=15, n_estimators=300; total time=   0.4s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=15, n_estimators=300; total time=   0.3s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=10, n_estimators=500; total time=   0.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=10, n_estimators=500; total time=   0.7s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=10, n_estimators=500; total time=   0.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=10, n_estimators=500; total time=   0.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=10, n_estimators=500; total time=   0.6s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(random_state=0),\n",
       "                   param_distributions={'max_depth': [5, 10, 15, 20, 25, 30],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 5, 10],\n",
       "                                        'min_samples_split': [2, 5, 10, 15,\n",
       "                                                              100],\n",
       "                                        'n_estimators': [100, 200, 300, 400,\n",
       "                                                         500, 600, 700, 800,\n",
       "                                                         900, 1000, 1100,\n",
       "                                                         1200]},\n",
       "                   random_state=0, scoring='neg_mean_squared_error', verbose=2)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f8fc5cc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 800,\n",
       " 'min_samples_split': 15,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 10}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "da518dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=rf_random.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e392527e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 1842.8567357317988\n",
      "RMSE: 2743.5186346069813\n"
     ]
    }
   ],
   "source": [
    "print('MAE:', metrics.mean_absolute_error(y_test,y_pred))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "faccf63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file = open('Model1.pkl','wb')\n",
    "pickle.dump(randomforest,file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
